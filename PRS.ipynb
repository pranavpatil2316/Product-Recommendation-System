# Step 1: Import required libraries
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Step 2: Upload CSV
from google.colab import files
uploaded = files.upload()  # Upload large_product_data.csv

# Step 3: Load dataset
df = pd.read_csv("large_product_data.csv")

# Step 4: TF-IDF Vectorization
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(df['description'])

# Step 5: Compute cosine similarity
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# Step 6: Recommend products
def recommend_products_by_partial_name(user_input, top_n=5):
    # Find partial matches (case insensitive)
    matches = df[df['product_name'].str.contains(user_input, case=False, na=False)]

    if matches.empty:
        print(f"❌ No product found containing '{user_input}'.")
        print("\n📝 Available products:")
        for name in df['product_name']:
            print("•", name)
        return

    if len(matches) > 1:
        print(f"\n🔍 Multiple products found for '{user_input}':")
        for i, name in enumerate(matches['product_name'], 1):
            print(f"{i}. {name}")
        choice = int(input("\nEnter the number of the product you want recommendations for: "))
        product_name = matches['product_name'].iloc[choice - 1]
    else:
        product_name = matches['product_name'].iloc[0]

    # Get index of selected product
    idx = df[df['product_name'] == product_name].index[0]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]
    recommended_indices = [i[0] for i in sim_scores]

    print(f"\n📦 Recommendations for '{product_name}':\n")
    for i in recommended_indices:
        print(f"➡ {df.loc[i, 'product_name']} - {df.loc[i, 'description']}")

# Step 7: Ask user input
user_input = input("\n💬 Enter a product name or keyword:\n> ").strip()
recommend_products_by_partial_name(user_input)
